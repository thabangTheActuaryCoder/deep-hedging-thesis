{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Deep Hedging in Incomplete Markets — GBM + Heston\n\n**MSc Thesis Experiment Runner**\n\nRuns the full deep hedging pipeline under **two market models**:\n- **GBM** (constant volatility, calibrated to S&P 500)\n- **Heston** (stochastic volatility, calibrated to S&P 500 / CBOE VIX)\n\n**Models:** FNN Cone (sigmoid allocation), GRU (direct positions), OLS Regression (direct positions)\n\n## Setup\n1. **Runtime → Change runtime type → A100 GPU** (Pro+ recommended)\n2. Click **Connect**\n3. Run **Cell 1** (clone + install)\n\n## Checkpoint / Resume\nAll progress is automatically checkpointed (Optuna trials in SQLite, per-seed metrics). If the runtime disconnects:\n1. Reconnect and re-run **Cell 1** (re-clone + install)\n2. Re-run the **same experiment cell** — it skips completed work and picks up where it left off"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 1: Clone repo and install dependencies\n!git clone https://github.com/thabangTheActuaryCoder/deep-hedging-thesis.git\n%cd deep-hedging-thesis\n!pip install -q torch numpy matplotlib optuna sqlalchemy scipy iisignature\n\nimport torch\nprint(f'\\nPython: {__import__(\"sys\").version}')\nprint(f'PyTorch: {torch.__version__}')\nprint(f'GPU available: {torch.cuda.is_available()}')\nif torch.cuda.is_available():\n    print(f'Device: {torch.cuda.get_device_name(0)}')\n    mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n    print(f'Memory: {mem:.1f} GB')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 2b: Backup & Restore — GitHub (primary) + local + Google Drive (Colab)\n# Works on both laptop and Colab. GitHub is the single source of truth.\n# Local backup: ~/deep_hedging_backup (survives repo re-clone)\n\nimport shutil, os, subprocess, datetime, pathlib\n\n# ── Auto-detect environment ─────────────────────────────────────────\nON_COLAB = os.path.exists('/content')\nREPO_DIR = '/content/deep-hedging-thesis' if ON_COLAB else os.getcwd()\nLOCAL_OUTPUTS = os.path.join(REPO_DIR, 'outputs')\nLOCAL_BACKUP = os.path.join(str(pathlib.Path.home()), 'deep_hedging_backup')\nGH_BRANCH = 'experiment-outputs'\n\n# ── Google Drive (Colab only) ──────────────────────────────────────\nDRIVE_BACKUP = None\nif ON_COLAB:\n    try:\n        from google.colab import drive\n        drive.mount('/content/drive')\n        DRIVE_BACKUP = '/content/drive/MyDrive/deep_hedging_outputs'\n        print('Google Drive mounted.')\n    except Exception as e:\n        print(f'Google Drive unavailable: {e}')\n\n# ── GitHub token ───────────────────────────────────────────────────\n# Colab: add GITHUB_TOKEN in Colab Secrets (key icon)\n# Laptop: export GITHUB_TOKEN=ghp_... in your shell\n_gh_token = os.environ.get('GITHUB_TOKEN', '')\nif not _gh_token:\n    try:\n        from google.colab import userdata\n        _gh_token = userdata.get('GITHUB_TOKEN')\n    except Exception:\n        pass\n\nif _gh_token:\n    _repo_url = f'https://{_gh_token}@github.com/thabangTheActuaryCoder/deep-hedging-thesis.git'\n    subprocess.run(['git', 'remote', 'set-url', 'origin', _repo_url],\n                   cwd=REPO_DIR, capture_output=True)\n    subprocess.run(['git', 'config', 'user.email', 'experiment@deep-hedging.run'],\n                   cwd=REPO_DIR, capture_output=True)\n    subprocess.run(['git', 'config', 'user.name', 'Experiment Runner'],\n                   cwd=REPO_DIR, capture_output=True)\n    print(f'GitHub configured (backup branch: {GH_BRANCH})')\nelse:\n    print('No GITHUB_TOKEN found — GitHub backup disabled.')\n    print('  Set it: export GITHUB_TOKEN=ghp_...')\n\n\n# ── Backup functions ────────────────────────────────────────────────\n\ndef backup_to_local():\n    \"\"\"Copy outputs/ to ~/deep_hedging_backup (survives repo re-clone).\"\"\"\n    if not os.path.exists(LOCAL_OUTPUTS):\n        print('No outputs to back up.'); return\n    if os.path.exists(LOCAL_BACKUP):\n        shutil.rmtree(LOCAL_BACKUP)\n    shutil.copytree(LOCAL_OUTPUTS, LOCAL_BACKUP)\n    n_files = sum(len(f) for _, _, f in os.walk(LOCAL_OUTPUTS))\n    print(f'Backed up {n_files} files to {LOCAL_BACKUP}')\n\n\ndef backup_to_github(message=None):\n    \"\"\"Commit outputs/ to the experiment-outputs orphan branch and push.\"\"\"\n    if not _gh_token:\n        print('GitHub backup skipped — no GITHUB_TOKEN set.'); return\n    if not os.path.exists(LOCAL_OUTPUTS):\n        print('No outputs to back up.'); return\n\n    ts = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')\n    msg = message or f'Backup outputs {ts}'\n\n    cur_branch = subprocess.run(\n        ['git', 'rev-parse', '--abbrev-ref', 'HEAD'],\n        cwd=REPO_DIR, capture_output=True, text=True\n    ).stdout.strip()\n\n    remote_check = subprocess.run(\n        ['git', 'ls-remote', '--heads', 'origin', GH_BRANCH],\n        cwd=REPO_DIR, capture_output=True, text=True\n    )\n    branch_exists = GH_BRANCH in remote_check.stdout\n\n    if branch_exists:\n        subprocess.run(['git', 'fetch', 'origin', GH_BRANCH], cwd=REPO_DIR, capture_output=True)\n        subprocess.run(['git', 'checkout', GH_BRANCH], cwd=REPO_DIR, capture_output=True)\n        subprocess.run(['git', 'reset', '--hard', f'origin/{GH_BRANCH}'], cwd=REPO_DIR, capture_output=True)\n    else:\n        subprocess.run(['git', 'checkout', '--orphan', GH_BRANCH], cwd=REPO_DIR, capture_output=True)\n        subprocess.run(['git', 'rm', '-rf', '.'], cwd=REPO_DIR, capture_output=True)\n\n    out_dest = os.path.join(REPO_DIR, 'outputs')\n    if os.path.exists(out_dest) and os.path.realpath(out_dest) != os.path.realpath(LOCAL_OUTPUTS):\n        shutil.rmtree(out_dest)\n        shutil.copytree(LOCAL_OUTPUTS, out_dest)\n\n    subprocess.run(['git', 'add', 'outputs/'], cwd=REPO_DIR, capture_output=True)\n    result = subprocess.run(\n        ['git', 'commit', '-m', msg],\n        cwd=REPO_DIR, capture_output=True, text=True\n    )\n    if result.returncode != 0 and 'nothing to commit' in (result.stdout + result.stderr):\n        print('GitHub: no new changes to push.')\n    else:\n        push = subprocess.run(\n            ['git', 'push', '-u', 'origin', GH_BRANCH, '--force'],\n            cwd=REPO_DIR, capture_output=True, text=True\n        )\n        if push.returncode == 0:\n            n_files = sum(len(f) for _, _, f in os.walk(LOCAL_OUTPUTS))\n            print(f'Backed up {n_files} files to GitHub (branch: {GH_BRANCH})')\n        else:\n            print(f'GitHub push failed: {push.stderr.strip()}')\n\n    subprocess.run(['git', 'checkout', cur_branch], cwd=REPO_DIR, capture_output=True)\n    subprocess.run(['git', 'checkout', '.'], cwd=REPO_DIR, capture_output=True)\n\n\ndef backup_to_drive():\n    \"\"\"Copy outputs/ to Google Drive (Colab only).\"\"\"\n    if not DRIVE_BACKUP:\n        print('Google Drive not available (not on Colab).'); return\n    if not os.path.exists(LOCAL_OUTPUTS):\n        print('No outputs to back up.'); return\n    if os.path.exists(DRIVE_BACKUP):\n        shutil.rmtree(DRIVE_BACKUP)\n    shutil.copytree(LOCAL_OUTPUTS, DRIVE_BACKUP)\n    n_files = sum(len(f) for _, _, f in os.walk(LOCAL_OUTPUTS))\n    print(f'Backed up {n_files} files to Google Drive')\n\n\ndef backup():\n    \"\"\"Back up to all available destinations.\"\"\"\n    backup_to_local()\n    backup_to_github()\n    if DRIVE_BACKUP:\n        backup_to_drive()\n\n\ndef restore_from_backup():\n    \"\"\"Restore outputs/ — tries GitHub, then local backup, then Drive.\"\"\"\n    if os.path.exists(LOCAL_OUTPUTS):\n        n = sum(len(f) for _, _, f in os.walk(LOCAL_OUTPUTS))\n        print(f'Outputs already exist locally ({n} files), skipping restore.')\n        return True\n\n    # 1. Try GitHub\n    if _gh_token:\n        print('Checking GitHub for backup...')\n        remote_check = subprocess.run(\n            ['git', 'ls-remote', '--heads', 'origin', GH_BRANCH],\n            cwd=REPO_DIR, capture_output=True, text=True\n        )\n        if GH_BRANCH in remote_check.stdout:\n            subprocess.run(['git', 'fetch', 'origin', GH_BRANCH],\n                         cwd=REPO_DIR, capture_output=True)\n            result = subprocess.run(\n                ['git', 'checkout', f'origin/{GH_BRANCH}', '--', 'outputs/'],\n                cwd=REPO_DIR, capture_output=True, text=True\n            )\n            if result.returncode == 0 and os.path.exists(LOCAL_OUTPUTS):\n                n = sum(len(f) for _, _, f in os.walk(LOCAL_OUTPUTS))\n                subprocess.run(['git', 'reset', 'HEAD', 'outputs/'],\n                             cwd=REPO_DIR, capture_output=True)\n                print(f'Restored {n} files from GitHub (branch: {GH_BRANCH})')\n                return True\n\n    # 2. Try local backup (~/deep_hedging_backup)\n    if os.path.exists(LOCAL_BACKUP):\n        print(f'Restoring from {LOCAL_BACKUP}...')\n        shutil.copytree(LOCAL_BACKUP, LOCAL_OUTPUTS)\n        n = sum(len(f) for _, _, f in os.walk(LOCAL_OUTPUTS))\n        print(f'Restored {n} files from local backup')\n        return True\n\n    # 3. Try Google Drive\n    if DRIVE_BACKUP and os.path.exists(DRIVE_BACKUP):\n        print('Restoring from Google Drive...')\n        shutil.copytree(DRIVE_BACKUP, LOCAL_OUTPUTS)\n        n = sum(len(f) for _, _, f in os.walk(LOCAL_OUTPUTS))\n        print(f'Restored {n} files from Google Drive')\n        return True\n\n    print('No backup found.')\n    return False\n\n\n# ── Auto-restore on cell run ───────────────────────────────────────\nrestore_from_backup()\nenv = 'Colab' if ON_COLAB else 'Local'\nprint(f'\\n[{env}] Backup functions ready:')\nprint(f'  backup()            — all destinations')\nprint(f'  backup_to_local()   — {LOCAL_BACKUP}')\nprint(f'  backup_to_github()  — GitHub (branch: {GH_BRANCH})')\nif DRIVE_BACKUP:\n    print(f'  backup_to_drive()   — Google Drive')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 3: Sanity check — all tests should pass\n!python -m pytest tests/test_validation.py -v",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 4 (QUICK TEST): ~10 min on A100, verifies both GBM + Heston pipelines\n!python run_experiment.py --quick --market_model both",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 5 (FULL RUN): Both GBM + Heston, 100k paths, lr=0.0001, MAE objective\n# Safe to re-run after disconnect — automatically resumes from checkpoints\n# FNN: searches start_width only (lr fixed at 1e-4)\n# GRU: searches num_layers, hidden_size, act_schedule (lr fixed at 1e-4)\n# Regression: closed-form OLS (no search)\n!python run_experiment.py \\\n    --market_model both \\\n    --paths 100000 \\\n    --N 200 \\\n    --epochs 1000 \\\n    --patience 15 \\\n    --batch_size 2048 \\\n    --n_trials 60 \\\n    --seeds 0 1 2 3 4\n\n# Auto-backup when experiment finishes (requires Cell 2b)\ntry:\n    backup()\nexcept NameError:\n    print('Tip: run Cell 2b first to enable automatic backups')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 6: Preview GBM validation plots\nfrom IPython.display import Image, display\nimport glob\n\nprint('=== GBM Validation Plots ===')\nfor img in sorted(glob.glob('outputs/gbm/plots_val/*.png')):\n    print(f'\\n--- {img} ---')\n    display(Image(filename=img, width=700))\n\nprint('\\n=== Heston Validation Plots ===')\nfor img in sorted(glob.glob('outputs/heston/plots_val/*.png')):\n    print(f'\\n--- {img} ---')\n    display(Image(filename=img, width=700))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 7: 3D hedge surface plots\nfrom IPython.display import Image, display\nimport glob\n\nfor market in ['gbm', 'heston']:\n    print(f'\\n=== {market.upper()} — 3D Hedge Surface Plots ===')\n    imgs = sorted(glob.glob(f'outputs/{market}/plots_3d/*.png'))\n    if imgs:\n        for img in imgs:\n            print(f'\\n--- {img} ---')\n            display(Image(filename=img, width=700))\n    else:\n        print(f'No PNG 3D plots found for {market}. Check outputs/{market}/plots_3d/ for HTML files.')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 8: Show validation metrics summary (both markets)\nimport json, os\n\nfor market in ['gbm', 'heston']:\n    path = f'outputs/{market}/metrics_summary.json'\n    if not os.path.exists(path):\n        print(f'{market.upper()}: No metrics found. Run the experiment first.')\n        continue\n\n    with open(path) as f:\n        summary = json.load(f)\n\n    print(f'\\n{\"=\"*60}')\n    print(f'  {market.upper()} — Best model: {summary[\"best_model\"]}')\n    print(f'{\"=\"*60}')\n\n    agg = summary['aggregated_val_metrics']\n    for model, metrics in agg.items():\n        mae = metrics.get('MAE', {})\n        mse = metrics.get('MSE', {})\n        print(f'  {model:12s}  MAE = {mae.get(\"mean\",0):.6f} +/- {mae.get(\"std\",0):.6f}  '\n              f'MSE = {mse.get(\"mean\",0):.6f} +/- {mse.get(\"std\",0):.6f}')\n\n    print(f'\\n  Best configs:')\n    for model, cfg in summary.get('best_configs', {}).items():\n        print(f'    {model}: {cfg}')\n\n# Cross-market comparison\ncross_path = 'outputs/cross_market/cross_market_metrics.json'\nif os.path.exists(cross_path):\n    with open(cross_path) as f:\n        cross = json.load(f)\n    print(f'\\n{\"=\"*60}')\n    print(f'  CROSS-MARKET COMPARISON')\n    print(f'{\"=\"*60}')\n    for market, models in cross.items():\n        if not isinstance(models, dict):\n            continue\n        for model, metrics in models.items():\n            if isinstance(metrics, dict) and 'test_MAE' in metrics:\n                print(f'  {market:8s} {model:12s}  test_MAE={metrics[\"test_MAE\"]:.6f}  test_MSE={metrics[\"test_MSE\"]:.6f}')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 9: Show CSV metrics tables (both markets)\nimport os\n\nfor market in ['gbm', 'heston']:\n    csv_path = f'outputs/{market}/val_metrics_summary.csv'\n    if os.path.exists(csv_path):\n        print(f'\\n=== {market.upper()} ===')\n        with open(csv_path) as f:\n            print(f.read())\n    else:\n        print(f'{market.upper()}: No CSV summary found.')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 10: Download all outputs as zip (includes GBM, Heston, cross_market)\nimport shutil\nfrom google.colab import files\n\nshutil.make_archive('outputs', 'zip', '.', 'outputs')\nfiles.download('outputs.zip')",
   "execution_count": null,
   "outputs": []
  }
 ]
}