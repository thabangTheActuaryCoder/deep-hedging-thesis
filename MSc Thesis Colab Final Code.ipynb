{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia8QQiwIrZX_"
      },
      "source": [
        "# Deep Hedging in Incomplete Markets — GBM & Heston\n",
        "\n",
        "**MSc Thesis Experiment Runner**\n",
        "\n",
        "Runs the full deep hedging pipeline under two market dynamics:\n",
        "- **GBM** (constant volatility, calibrated to S&P 500)\n",
        "- **Heston** (stochastic volatility, calibrated to S&P 500)\n",
        "\n",
        "## Setup\n",
        "1. **Runtime → Change runtime type → A100 GPU** (Pro+ recommended)\n",
        "2. Click **Connect**\n",
        "3. Run **Cell 1** (clone + install)\n",
        "\n",
        "## Two ways to run\n",
        "- **Option A (Browser):** Run cells directly in this notebook\n",
        "- **Option B (VS Code):** Run Cell 2 to get an SSH tunnel, then connect VS Code and use the terminal\n",
        "\n",
        "## Checkpoint / Resume\n",
        "All progress is automatically checkpointed (Optuna trials in SQLite, per-seed metrics, cached features). If the runtime disconnects mid-run:\n",
        "1. Reconnect and re-run **Cell 1** (re-clone + install)\n",
        "2. Re-run the **same experiment cell** — it skips completed work and picks up where it left off\n",
        "\n",
        "## Safe practice for long runs\n",
        "For multi-hour or overnight training:\n",
        "- **Print/log progress regularly.** The pipeline prints each Optuna trial, seed, and stage as it completes — watch the output to monitor progress.\n",
        "- **Save checkpoints to Google Drive.** Copy the `outputs/` directory to Drive periodically so results survive runtime recycling (see Cell 2b below).\n",
        "- **Assume sessions can still end and plan to resume.** Even with Pro+, Colab may reclaim GPUs after ~12 hours. The checkpoint system ensures no work is lost — just reconnect and re-run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6xKYYJUrZYA",
        "outputId": "6f8c1fe9-2417-462e-9909-396325f83341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Cell 1: Clone repo and install dependencies\n",
        "!git clone https://github.com/thabangTheActuaryCoder/deep-hedging-thesis.git\n",
        "%cd deep-hedging-thesis\n",
        "!pip install -q torch numpy matplotlib optuna sqlalchemy\n",
        "\n",
        "import torch\n",
        "print(f'\\nPython: {__import__(\"sys\").version}')\n",
        "print(f'PyTorch: {torch.__version__}')\n",
        "print(f'GPU available: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'Device: {torch.cuda.get_device_name(0)}')\n",
        "    mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f'Memory: {mem:.1f} GB')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-hedging-thesis'...\n",
            "remote: Enumerating objects: 217, done.\u001b[K\n",
            "remote: Counting objects: 100% (217/217), done.\u001b[K\n",
            "remote: Compressing objects: 100% (136/136), done.\u001b[K\n",
            "remote: Total 217 (delta 95), reused 198 (delta 78), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (217/217), 4.08 MiB | 17.42 MiB/s, done.\n",
            "Resolving deltas: 100% (95/95), done.\n",
            "/content/deep-hedging-thesis/deep-hedging-thesis\n",
            "\n",
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "PyTorch: 2.9.0+cu126\n",
            "GPU available: True\n",
            "Device: NVIDIA A100-SXM4-40GB\n",
            "Memory: 42.5 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2b (optional): Mount Google Drive and sync checkpoints\n",
        "# Run this BEFORE the experiment to back up outputs to Drive automatically.\n",
        "# On resume after disconnect, it restores outputs from Drive so nothing is lost.\n",
        "\n",
        "from google.colab import drive\n",
        "import shutil, os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DRIVE_BACKUP = '/content/drive/MyDrive/deep_hedging_outputs'\n",
        "LOCAL_OUTPUTS = '/content/deep-hedging-thesis/outputs'\n",
        "\n",
        "# Restore from Drive if outputs exist there but not locally\n",
        "if os.path.exists(DRIVE_BACKUP) and not os.path.exists(LOCAL_OUTPUTS):\n",
        "    print('Restoring outputs from Google Drive...')\n",
        "    shutil.copytree(DRIVE_BACKUP, LOCAL_OUTPUTS)\n",
        "    print(f'Restored {sum(len(f) for _, _, f in os.walk(LOCAL_OUTPUTS))} files')\n",
        "\n",
        "def backup_to_drive():\n",
        "    \"\"\"Call this periodically or after the experiment to save outputs to Drive.\"\"\"\n",
        "    if os.path.exists(LOCAL_OUTPUTS):\n",
        "        if os.path.exists(DRIVE_BACKUP):\n",
        "            shutil.rmtree(DRIVE_BACKUP)\n",
        "        shutil.copytree(LOCAL_OUTPUTS, DRIVE_BACKUP)\n",
        "        print(f'Backed up outputs to {DRIVE_BACKUP}')\n",
        "\n",
        "print('Drive mounted. Call backup_to_drive() anytime to save outputs.')"
      ],
      "metadata": {
        "id": "Xn80ttWArZYB",
        "outputId": "72b5231a-9b08-4eea-a434-6b2a0eb92a75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive mounted. Call backup_to_drive() anytime to save outputs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Sanity check — all tests should pass\n",
        "!python -m pytest tests/test_validation.py -v"
      ],
      "metadata": {
        "id": "U4Tie_99rZYB",
        "outputId": "89d58ae7-a8dc-4208-c9d4-38b6c8c18bc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/deep-hedging-thesis/deep-hedging-thesis\n",
            "plugins: anyio-4.12.1, typeguard-4.4.4, langsmith-0.6.8\n",
            "collected 13 items                                                             \u001b[0m\n",
            "\n",
            "tests/test_validation.py::TestNoLookAhead::test_base_features_no_lookahead \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
            "tests/test_validation.py::TestNoLookAhead::test_signature_features_no_lookahead \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
            "tests/test_validation.py::TestNoLookAhead::test_signature_at_zero \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
            "tests/test_validation.py::TestSelfFinancing::test_portfolio_update \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
            "tests/test_validation.py::TestSelfFinancing::test_path_terminal_consistency \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
            "tests/test_validation.py::TestSelfFinancing::test_no_future_prices_in_delta \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
            "tests/test_validation.py::TestReproducibility::test_market_simulation \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
            "tests/test_validation.py::TestReproducibility::test_payoff_reproducibility \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
            "tests/test_validation.py::TestReproducibility::test_split_reproducibility \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
            "tests/test_validation.py::TestReproducibility::test_model_forward_reproducibility \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
            "tests/test_validation.py::TestControllerCausality::test_controller_input_excludes_future \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
            "tests/test_validation.py::TestLRGrid::test_lr_values \u001b[32mPASSED\u001b[0m\u001b[32m              [ 92%]\u001b[0m\n",
            "tests/test_validation.py::TestLSTMConsistency::test_lstm_full_vs_slice \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m13 passed\u001b[0m\u001b[32m in 1.89s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVdvRqknrZYB",
        "outputId": "48dc9541-c442-4ca4-b1e3-41a6fb0078aa"
      },
      "source": [
        "# Cell 5 (FULL RUN): both GBM + Heston, 100k paths, ~4-8 hours on A100\n",
        "# Safe to re-run after disconnect — automatically resumes from checkpoints\n",
        "!python run_experiment.py \\\n",
        "    --paths 100000 \\\n",
        "    --N 200 \\\n",
        "    --epochs 1000 \\\n",
        "    --patience 15 \\\n",
        "    --batch_size 2048 \\\n",
        "    --n_trials 60 \\\n",
        "    --seeds 0 1 2 3 4 \\\n",
        "    --substeps 0 5 10 \\\n",
        "    --market_model both\n",
        "\n",
        "# Auto-backup to Drive when experiment finishes (requires Cell 2b)\n",
        "try:\n",
        "    backup_to_drive()\n",
        "except NameError:\n",
        "    print('Tip: run Cell 2b first to enable automatic Google Drive backups')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Quick mode: False\n",
            "Market model: both\n",
            "Paths=100000  Split hash=0d2ec472ec087faf\n",
            "Train=60000  Val=20000  Test=20000\n",
            "\n",
            "============================================================\n",
            "  MARKET MODEL: GBM (calibrated)\n",
            "============================================================\n",
            "  GBM: r=0.043, vols=[0.18, 0.22], extra_vol=0.06\n",
            "\n",
            "============================================================\n",
            "  Pipeline: GBM market  (m_brownian=3)\n",
            "============================================================\n",
            "\n",
            "=== [gbm] Step 2: Feature Construction ===\n",
            "  Feature dim: 24\n",
            "\n",
            "=== [gbm] Step 3: Stage 1 – Optuna HP Search (TPE) ===\n",
            "\n",
            "--- FNN ---\n",
            "\n",
            "  Optuna search for FNN: up to 60 trials (search space = 108 configs)\n",
            "    Trial 0: depth=5 width=256 act=alt_relu_tanh lr=0.0003 -> CVaR95=0.074074  MSE=0.002298\n",
            "    Trial 1: depth=3 width=128 act=tanh_all lr=0.0003 -> CVaR95=0.069650  MSE=0.002441\n",
            "    Trial 2: depth=5 width=256 act=alt_tanh_relu lr=0.003 -> CVaR95=0.073402  MSE=0.002483\n",
            "    Trial 3: depth=3 width=64 act=relu_all lr=0.001 -> CVaR95=0.071358  MSE=0.002318\n",
            "    Trial 4: depth=3 width=128 act=relu_all lr=0.0003 -> CVaR95=0.072266  MSE=0.002270\n",
            "    Trial 5: depth=5 width=256 act=tanh_all lr=0.001 -> CVaR95=0.068911  MSE=0.002549\n",
            "    Trial 6: depth=7 width=256 act=relu_all lr=0.001 -> CVaR95=0.075111  MSE=0.002354\n",
            "    Trial 7: depth=7 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068922  MSE=0.002765\n",
            "    Trial 8: depth=7 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068922  MSE=0.002765\n",
            "    Trial 9: depth=5 width=256 act=relu_all lr=0.001 -> CVaR95=0.074401  MSE=0.002289\n",
            "    Trial 10: depth=5 width=64 act=alt_relu_tanh lr=0.001 -> CVaR95=0.071288  MSE=0.002257\n",
            "    Trial 11: depth=7 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068922  MSE=0.002765\n",
            "    Trial 12: depth=7 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068922  MSE=0.002765\n",
            "    Trial 13: depth=5 width=256 act=tanh_all lr=0.001 -> CVaR95=0.068911  MSE=0.002549\n",
            "    Trial 14: depth=5 width=128 act=alt_tanh_relu lr=0.001 -> CVaR95=0.071242  MSE=0.002283\n",
            "    Trial 15: depth=5 width=64 act=tanh_all lr=0.001 -> CVaR95=0.071142  MSE=0.002671\n",
            "    Trial 16: depth=5 width=256 act=tanh_all lr=0.001 -> CVaR95=0.068911  MSE=0.002549\n",
            "    Trial 17: depth=5 width=256 act=tanh_all lr=0.001 -> CVaR95=0.068911  MSE=0.002549\n",
            "    Trial 18: depth=5 width=128 act=alt_tanh_relu lr=0.001 -> CVaR95=0.071242  MSE=0.002283\n",
            "    Trial 19: depth=5 width=64 act=alt_relu_tanh lr=0.001 -> CVaR95=0.071288  MSE=0.002257\n",
            "    Trial 20: depth=3 width=256 act=tanh_all lr=0.0003 -> CVaR95=0.071951  MSE=0.002472\n",
            "    Trial 21: depth=5 width=256 act=tanh_all lr=0.001 -> CVaR95=0.068911  MSE=0.002549\n",
            "    Trial 22: depth=5 width=256 act=tanh_all lr=0.001 -> CVaR95=0.068911  MSE=0.002549\n",
            "    Trial 23: depth=5 width=256 act=tanh_all lr=0.001 -> CVaR95=0.068911  MSE=0.002549\n",
            "    Trial 24: depth=5 width=256 act=tanh_all lr=0.001 -> CVaR95=0.068911  MSE=0.002549\n",
            "    Trial 25: depth=5 width=256 act=tanh_all lr=0.001 -> CVaR95=0.068911  MSE=0.002549\n",
            "    Trial 26: depth=5 width=256 act=tanh_all lr=0.001 -> CVaR95=0.068911  MSE=0.002549\n",
            "    Trial 27: depth=5 width=256 act=alt_relu_tanh lr=0.001 -> CVaR95=0.071774  MSE=0.002310\n",
            "    Trial 28: depth=3 width=64 act=alt_tanh_relu lr=0.001 -> CVaR95=0.069662  MSE=0.002373\n",
            "    Trial 29: depth=5 width=128 act=alt_relu_tanh lr=0.0003 -> CVaR95=0.072127  MSE=0.002302\n",
            "    Trial 30: depth=5 width=256 act=tanh_all lr=0.001 -> CVaR95=0.068911  MSE=0.002549\n",
            "    Trial 31: depth=5 width=256 act=tanh_all lr=0.001 -> CVaR95=0.068911  MSE=0.002549\n",
            "    Trial 32: depth=5 width=256 act=tanh_all lr=0.001 -> CVaR95=0.068911  MSE=0.002549\n",
            "    Trial 33: depth=5 width=256 act=tanh_all lr=0.0003 -> CVaR95=0.070949  MSE=0.002364\n",
            "    Trial 34: depth=5 width=256 act=tanh_all lr=0.001 -> CVaR95=0.068911  MSE=0.002549\n",
            "    Trial 35: depth=3 width=256 act=tanh_all lr=0.001 -> CVaR95=0.072181  MSE=0.002564\n",
            "    Trial 36: depth=5 width=128 act=relu_all lr=0.0003 -> CVaR95=0.073176  MSE=0.002275\n",
            "    Trial 37: depth=5 width=256 act=alt_tanh_relu lr=0.001 -> CVaR95=0.072150  MSE=0.002306\n",
            "    Trial 38: depth=3 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068753  MSE=0.002659\n",
            "    Trial 39: depth=3 width=64 act=relu_all lr=0.003 -> CVaR95=0.073790  MSE=0.002266\n",
            "    Trial 40: depth=3 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068753  MSE=0.002659\n",
            "    Trial 41: depth=3 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068753  MSE=0.002659\n",
            "    Trial 42: depth=3 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068753  MSE=0.002659\n",
            "    Trial 43: depth=3 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068753  MSE=0.002659\n",
            "    Trial 44: depth=3 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068753  MSE=0.002659\n",
            "    Trial 45: depth=3 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068753  MSE=0.002659\n",
            "    Trial 46: depth=3 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068753  MSE=0.002659\n",
            "    Trial 47: depth=3 width=128 act=relu_all lr=0.003 -> CVaR95=0.072883  MSE=0.002311\n",
            "    Trial 48: depth=3 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068753  MSE=0.002659\n",
            "    Trial 49: depth=3 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068753  MSE=0.002659\n",
            "    Trial 50: depth=3 width=64 act=alt_relu_tanh lr=0.003 -> CVaR95=0.073009  MSE=0.002323\n",
            "    Trial 51: depth=3 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068753  MSE=0.002659\n",
            "    Trial 52: depth=3 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068753  MSE=0.002659\n",
            "    Trial 53: depth=3 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068753  MSE=0.002659\n",
            "    Trial 54: depth=3 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068753  MSE=0.002659\n",
            "    Trial 55: depth=3 width=256 act=alt_tanh_relu lr=0.003 -> CVaR95=0.070648  MSE=0.002441\n",
            "    Trial 56: depth=3 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068753  MSE=0.002659\n",
            "    Trial 57: depth=7 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068922  MSE=0.002765\n",
            "    Trial 58: depth=3 width=256 act=tanh_all lr=0.003 -> CVaR95=0.068753  MSE=0.002659\n",
            "    Trial 59: depth=3 width=128 act=tanh_all lr=0.003 -> CVaR95=0.072957  MSE=0.002632\n",
            "\n",
            "  Best FNN: depth=3 width=256 act=tanh_all lr=0.003 CVaR95=0.068753  MSE=0.002659\n",
            "  [saved Stage 1 progress: ['FNN']]\n",
            "\n",
            "--- LSTM ---\n",
            "\n",
            "  Optuna search for LSTM: up to 60 trials (search space = 108 configs)\n",
            "    OOM -> retrying with batch_size=1024\n",
            "    FAILED (retry): CUDA out of memory. Tried to allocate 23.85 GiB. GPU 0 has a total capacity of 39.56 GiB of which 11.22 GiB is free. Process 79815 has 28.32 GiB memory in use. Of the allocated memory 22.08 GiB is allocated by PyTorch, and 5.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "    Trial 0: depth=5 width=256 act=alt_relu_tanh lr=0.0003 -> CVaR95=inf  MSE=inf\n",
            "    OOM -> retrying with batch_size=1024\n",
            "    FAILED (retry): CUDA out of memory. Tried to allocate 42.19 GiB. GPU 0 has a total capacity of 39.56 GiB of which 23.21 GiB is free. Process 79815 has 16.33 GiB memory in use. Of the allocated memory 11.98 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "    Trial 1: depth=3 width=128 act=tanh_all lr=0.0003 -> CVaR95=inf  MSE=inf\n",
            "    OOM -> retrying with batch_size=1024\n",
            "    FAILED (retry): CUDA out of memory. Tried to allocate 23.85 GiB. GPU 0 has a total capacity of 39.56 GiB of which 11.42 GiB is free. Process 79815 has 28.12 GiB memory in use. Of the allocated memory 22.08 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "    Trial 2: depth=5 width=256 act=alt_tanh_relu lr=0.003 -> CVaR95=inf  MSE=inf\n",
            "    Trial 3: depth=3 width=64 act=relu_all lr=0.001 -> CVaR95=0.242900  MSE=0.004344\n",
            "    OOM -> retrying with batch_size=1024\n",
            "    FAILED (retry): CUDA out of memory. Tried to allocate 42.19 GiB. GPU 0 has a total capacity of 39.56 GiB of which 25.53 GiB is free. Process 79815 has 14.02 GiB memory in use. Of the allocated memory 11.97 GiB is allocated by PyTorch, and 1.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "    Trial 4: depth=3 width=128 act=relu_all lr=0.0003 -> CVaR95=inf  MSE=inf\n",
            "    OOM -> retrying with batch_size=1024\n",
            "    FAILED (retry): CUDA out of memory. Tried to allocate 23.85 GiB. GPU 0 has a total capacity of 39.56 GiB of which 14.04 GiB is free. Process 79815 has 25.51 GiB memory in use. Of the allocated memory 22.08 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "    Trial 5: depth=5 width=256 act=tanh_all lr=0.001 -> CVaR95=inf  MSE=inf\n",
            "    OOM -> retrying with batch_size=1024\n",
            "    FAILED (retry): CUDA out of memory. Tried to allocate 8.04 GiB. GPU 0 has a total capacity of 39.56 GiB of which 2.48 GiB is free. Process 79815 has 37.07 GiB memory in use. Of the allocated memory 29.67 GiB is allocated by PyTorch, and 6.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "    Trial 6: depth=7 width=256 act=relu_all lr=0.001 -> CVaR95=inf  MSE=inf\n",
            "    OOM -> retrying with batch_size=1024\n",
            "    FAILED (retry): CUDA out of memory. Tried to allocate 8.04 GiB. GPU 0 has a total capacity of 39.56 GiB of which 2.72 GiB is free. Process 79815 has 36.83 GiB memory in use. Of the allocated memory 29.66 GiB is allocated by PyTorch, and 6.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "    Trial 7: depth=7 width=256 act=tanh_all lr=0.003 -> CVaR95=inf  MSE=inf\n",
            "    OOM -> retrying with batch_size=1024\n",
            "    FAILED (retry): CUDA out of memory. Tried to allocate 8.04 GiB. GPU 0 has a total capacity of 39.56 GiB of which 2.72 GiB is free. Process 79815 has 36.83 GiB memory in use. Of the allocated memory 29.66 GiB is allocated by PyTorch, and 6.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "    Trial 8: depth=7 width=256 act=tanh_all lr=0.003 -> CVaR95=inf  MSE=inf\n",
            "    OOM -> retrying with batch_size=1024\n",
            "    FAILED (retry): CUDA out of memory. Tried to allocate 23.85 GiB. GPU 0 has a total capacity of 39.56 GiB of which 11.78 GiB is free. Process 79815 has 27.77 GiB memory in use. Of the allocated memory 22.08 GiB is allocated by PyTorch, and 5.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "    Trial 9: depth=5 width=256 act=relu_all lr=0.001 -> CVaR95=inf  MSE=inf\n",
            "    Trial 10: depth=3 width=64 act=alt_relu_tanh lr=0.001 -> CVaR95=0.492964  MSE=0.005058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umjtxRsvrZYB"
      },
      "source": [
        "# Cell 6: Preview GBM validation plots\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "print('=== GBM Validation Plots ===')\n",
        "for img in sorted(glob.glob('outputs/gbm/plots_val/*.png')):\n",
        "    print(f'\\n--- {img} ---')\n",
        "    display(Image(filename=img, width=700))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfllR2mdrZYB"
      },
      "source": [
        "# Cell 7: Preview Heston validation plots\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "print('=== Heston Validation Plots ===')\n",
        "for img in sorted(glob.glob('outputs/heston/plots_val/*.png')):\n",
        "    print(f'\\n--- {img} ---')\n",
        "    display(Image(filename=img, width=700))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BowC4OZHrZYB"
      },
      "source": [
        "# Cell 8: Heston stochastic volatility diagnostic plots\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "print('=== Heston Stochastic Volatility Diagnostics ===')\n",
        "for img in sorted(glob.glob('outputs/heston/plots_heston/*.png')):\n",
        "    print(f'\\n--- {img} ---')\n",
        "    display(Image(filename=img, width=700))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGZxsNlyrZYC"
      },
      "source": [
        "# Cell 9: GBM vs Heston comparison plots\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "print('=== GBM vs Heston Comparison ===')\n",
        "for img in sorted(glob.glob('outputs/comparison/*.png')):\n",
        "    print(f'\\n--- {img} ---')\n",
        "    display(Image(filename=img, width=700))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMsgJ9tWrZYC"
      },
      "source": [
        "# Cell 10: 3D delta surface plots\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "for label, pattern in [('GBM', 'outputs/gbm/plots_3d/*.png'),\n",
        "                       ('Heston', 'outputs/heston/plots_3d/*.png')]:\n",
        "    imgs = sorted(glob.glob(pattern))\n",
        "    if imgs:\n",
        "        print(f'\\n=== {label} 3D Delta Surfaces ===')\n",
        "        for img in imgs:\n",
        "            print(f'\\n--- {img} ---')\n",
        "            display(Image(filename=img, width=700))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tmaYBNMrZYC"
      },
      "source": [
        "# Cell 11: Show validation metrics (both market models)\n",
        "import json, os\n",
        "\n",
        "for market in ['gbm', 'heston']:\n",
        "    path = f'outputs/{market}/val_metrics.json'\n",
        "    if not os.path.exists(path):\n",
        "        continue\n",
        "    with open(path) as f:\n",
        "        metrics = json.load(f)\n",
        "    print(f'\\n{\"=\"*50}')\n",
        "    print(f'  {market.upper()} — Best model: {metrics[\"best_model\"]}')\n",
        "    print(f'{\"=\"*50}')\n",
        "    for model, agg in metrics['aggregated_val_metrics'].items():\n",
        "        cvar = agg['CVaR95_shortfall']\n",
        "        mse = agg['MSE']\n",
        "        print(f'  {model:6s}  CVaR95 = {cvar[\"mean\"]:.6f} +/- {cvar[\"std\"]:.6f}  '\n",
        "              f'MSE = {mse[\"mean\"]:.6f} +/- {mse[\"std\"]:.6f}')\n",
        "\n",
        "summary_path = 'outputs/metrics_summary.json'\n",
        "if os.path.exists(summary_path):\n",
        "    with open(summary_path) as f:\n",
        "        combined = json.load(f)\n",
        "    print(f'\\n{\"=\"*50}')\n",
        "    print('  COMBINED SUMMARY')\n",
        "    print(f'{\"=\"*50}')\n",
        "    for market, agg in combined.items():\n",
        "        print(f'\\n  [{market.upper()}]')\n",
        "        for model, m in agg.items():\n",
        "            cvar = m.get('CVaR95_shortfall', {})\n",
        "            if isinstance(cvar, dict):\n",
        "                print(f'    {model:6s}  CVaR95 = {cvar.get(\"mean\",0):.6f} +/- {cvar.get(\"std\",0):.6f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV8ccx67rZYC"
      },
      "source": [
        "## Replot (optional)\n",
        "\n",
        "If you want to adjust figure dimensions, colors, grids, or fonts without\n",
        "rerunning the experiment, edit the `STYLE` dict in `replot.py` and rerun\n",
        "Cell 13 below. The data was saved during the experiment."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_XWE850rZYC"
      },
      "source": [
        "# Cell 13: Regenerate comparison plots from saved data (edit STYLE in replot.py first)\n",
        "!python replot.py --data outputs/comparison/comparison_data.pt \\\n",
        "                  --metrics outputs/metrics_summary.json \\\n",
        "                  --out outputs/comparison\n",
        "\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "for img in sorted(glob.glob('outputs/comparison/*.png')):\n",
        "    print(f'\\n--- {img} ---')\n",
        "    display(Image(filename=img, width=700))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41UVtXXnrZYC"
      },
      "source": [
        "# Cell 14: Download all outputs as zip\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "shutil.make_archive('outputs', 'zip', '.', 'outputs')\n",
        "files.download('outputs.zip')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}