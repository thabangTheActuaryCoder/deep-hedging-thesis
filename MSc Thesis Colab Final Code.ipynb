{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Deep Hedging in Incomplete Markets — GBM + Heston\n\n**MSc Thesis Experiment Runner**\n\nRuns the full deep hedging pipeline under **two market models**:\n- **GBM** (constant volatility, calibrated to S&P 500)\n- **Heston** (stochastic volatility, calibrated to S&P 500 / CBOE VIX)\n\n**Models:** FNN Cone (sigmoid allocation), GRU (direct positions), OLS Regression (direct positions)\n\n**Features:** FNN uses base + signature features (level 3, feat_dim=12). GRU/Regression use base features only (feat_dim=3).\n\n## First Run\n1. **Runtime → Change runtime type → A100 GPU** (Pro+ recommended)\n2. Run **Cell 1** (clone + install)\n3. Run **Cell 2** (fresh start — clears Drive + local outputs)\n4. Run **Cell 4** (sanity check — tests)\n5. Run **Cell 5** (quick test) OR **Cells 6–11** (full run, one model per cell)\n\n## Resume After Disconnect\n1. **Runtime → Change runtime type → A100 GPU**\n2. Run **Cell 1** (clone + install)\n3. **Skip Cell 2** — run **Cell 3** instead (restores saved outputs from Drive)\n4. Run **Cell 4** (sanity check)\n5. Re-run the model cell that was interrupted — it starts that model fresh while keeping all completed models' results. Then continue with remaining cells.\n\n## Full Run — Sequential Model Cells (Cells 6–11)\nEach model runs as a **separate subprocess** so GPU/CPU memory is fully freed between them. After each cell, outputs are backed up to Google Drive. Completed models are automatically skipped on re-run.\n\n| Cell | Market | Model |\n|------|--------|-------|\n| 6 | GBM | Regression |\n| 7 | GBM | GRU |\n| 8 | GBM | FNN |\n| 9 | Heston | Regression |\n| 10 | Heston | GRU |\n| 11 | Heston | FNN |\n\nThe last cell for each market generates comparison plots using saved results from all prior model runs."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 1: Clone repo and install dependencies\n!git clone https://github.com/thabangTheActuaryCoder/deep-hedging-thesis.git\n%cd deep-hedging-thesis\n!pip install -q torch numpy matplotlib optuna sqlalchemy scipy iisignature\n\nimport torch\nprint(f'\\nPython: {__import__(\"sys\").version}')\nprint(f'PyTorch: {torch.__version__}')\nprint(f'GPU available: {torch.cuda.is_available()}')\nif torch.cuda.is_available():\n    print(f'Device: {torch.cuda.get_device_name(0)}')\n    mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n    print(f'Memory: {mem:.1f} GB')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 2: FRESH START ONLY — clears ALL previous outputs (Drive + local)\n# ⚠️ Skip this cell when resuming after a disconnect! Use Cell 3 instead.\nimport shutil, os\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nDRIVE_BACKUP = '/content/drive/MyDrive/deep_hedging_outputs'\nif os.path.exists(DRIVE_BACKUP):\n    shutil.rmtree(DRIVE_BACKUP)\n    print(f'Cleared previous outputs from Google Drive ({DRIVE_BACKUP})')\nelse:\n    print(f'Google Drive clean — no previous outputs found.')\n\nLOCAL_OUTPUTS = '/content/deep-hedging-thesis/outputs'\nif os.path.exists(LOCAL_OUTPUTS):\n    shutil.rmtree(LOCAL_OUTPUTS)\n    print(f'Cleared local outputs ({LOCAL_OUTPUTS})')\n\nprint('Ready for a fresh experiment run.')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 3: RESUME AFTER DISCONNECT — restores saved outputs from Google Drive\n# Run this instead of Cell 2 when reconnecting after a runtime timeout/crash.\n# Completed models will be skipped automatically; interrupted models retrain from scratch.\nimport shutil, os\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nDRIVE_BACKUP = '/content/drive/MyDrive/deep_hedging_outputs'\nLOCAL_OUTPUTS = '/content/deep-hedging-thesis/outputs'\n\nif os.path.exists(DRIVE_BACKUP):\n    # Restore Drive backup to local outputs\n    if os.path.exists(LOCAL_OUTPUTS):\n        shutil.rmtree(LOCAL_OUTPUTS)\n    shutil.copytree(DRIVE_BACKUP, LOCAL_OUTPUTS)\n\n    # Count what's been completed\n    for market in ['gbm', 'heston']:\n        ckpt_dir = os.path.join(LOCAL_OUTPUTS, market, 'checkpoints')\n        if os.path.exists(ckpt_dir):\n            ckpts = [f for f in os.listdir(ckpt_dir) if f.endswith('.pt')]\n            models_done = [f.replace('_seed0.pt', '') for f in ckpts]\n            print(f'  {market.upper()}: restored {len(ckpts)} checkpoints — {models_done}')\n        else:\n            print(f'  {market.upper()}: no checkpoints found')\n\n    print(f'\\nRestored outputs from Google Drive. Re-run the interrupted model cell to continue.')\nelse:\n    print('No previous outputs found on Google Drive. Run Cell 2 for a fresh start.')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 4: Sanity check — all tests should pass\n!python -m pytest tests/test_validation.py -v",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 5 (QUICK TEST): ~10 min on A100, verifies both GBM + Heston pipelines\n!python run_experiment.py --quick --market_model both",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 6 (GBM — Regression): Closed-form OLS, ~2 min\n!python run_experiment.py --models regression --market_model gbm \\\n    --paths 100000 --epochs 1000 --patience 15 --batch_size 2048 --seeds 0\n\n# Backup to Google Drive (survives runtime disconnects)\n!cp -r outputs/ /content/drive/MyDrive/deep_hedging_outputs/\nprint('Backed up to Google Drive.')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 7 (GBM — GRU): Optuna HP search + seed robustness\n!python run_experiment.py --models gru --market_model gbm \\\n    --paths 100000 --epochs 1000 --patience 15 --batch_size 2048 --n_trials 60 --seeds 0\n\n# Backup to Google Drive (survives runtime disconnects)\n!cp -r outputs/ /content/drive/MyDrive/deep_hedging_outputs/\nprint('Backed up to Google Drive.')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 8 (GBM — FNN): Optuna HP search + seed robustness (signature features)\n# Last GBM cell — generates comparison plots with all 3 models\n!python run_experiment.py --models fnn --market_model gbm \\\n    --paths 100000 --epochs 1000 --patience 15 --batch_size 2048 --n_trials 60 --seeds 0\n\n# Backup to Google Drive (survives runtime disconnects)\n!cp -r outputs/ /content/drive/MyDrive/deep_hedging_outputs/\nprint('Backed up to Google Drive.')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 9 (Heston — Regression): Closed-form OLS, ~2 min\n!python run_experiment.py --models regression --market_model heston \\\n    --paths 100000 --epochs 1000 --patience 15 --batch_size 2048 --seeds 0\n\n# Backup to Google Drive (survives runtime disconnects)\n!cp -r outputs/ /content/drive/MyDrive/deep_hedging_outputs/\nprint('Backed up to Google Drive.')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 10 (Heston — GRU): Optuna HP search + seed robustness\n!python run_experiment.py --models gru --market_model heston \\\n    --paths 100000 --epochs 1000 --patience 15 --batch_size 2048 --n_trials 60 --seeds 0\n\n# Backup to Google Drive (survives runtime disconnects)\n!cp -r outputs/ /content/drive/MyDrive/deep_hedging_outputs/\nprint('Backed up to Google Drive.')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 11 (Heston — FNN): Optuna HP search + seed robustness (signature features)\n# Last Heston cell — generates comparison plots with all 3 models\n!python run_experiment.py --models fnn --market_model heston \\\n    --paths 100000 --epochs 1000 --patience 15 --batch_size 2048 --n_trials 60 --seeds 0\n\n# Backup to Google Drive (survives runtime disconnects)\n!cp -r outputs/ /content/drive/MyDrive/deep_hedging_outputs/\nprint('Backed up to Google Drive.')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 12: Preview validation + test plots (both markets)\nfrom IPython.display import Image, display\nimport glob\n\nfor market in ['gbm', 'heston']:\n    for split, folder in [('Validation', 'plots_val'), ('Test', 'plots_test')]:\n        imgs = sorted(glob.glob(f'outputs/{market}/{folder}/*.png'))\n        if imgs:\n            print(f'\\n=== {market.upper()} — {split} Plots ===')\n            for img in imgs:\n                print(f'\\n--- {img} ---')\n                display(Image(filename=img, width=700))\n        else:\n            print(f'\\n{market.upper()} — No {split.lower()} plots found yet.')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 13: 3D hedge surface plots\nfrom IPython.display import Image, display\nimport glob\n\nfor market in ['gbm', 'heston']:\n    print(f'\\n=== {market.upper()} — 3D Hedge Surface Plots ===')\n    imgs = sorted(glob.glob(f'outputs/{market}/plots_3d/*.png'))\n    if imgs:\n        for img in imgs:\n            print(f'\\n--- {img} ---')\n            display(Image(filename=img, width=700))\n    else:\n        print(f'No PNG 3D plots found for {market}. Check outputs/{market}/plots_3d/ for HTML files.')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 14: Show validation + test metrics summary (both markets)\nimport json, os\n\nfor market in ['gbm', 'heston']:\n    path = f'outputs/{market}/metrics_summary.json'\n    if not os.path.exists(path):\n        print(f'{market.upper()}: No metrics found. Run the experiment first.')\n        continue\n\n    with open(path) as f:\n        summary = json.load(f)\n\n    best_val = summary.get('best_model_val', summary.get('best_model', '?'))\n    best_test = summary.get('best_model_test', '?')\n\n    print(f'\\n{\"=\"*60}')\n    print(f'  {market.upper()} — Best model (val): {best_val}  |  Best model (test): {best_test}')\n    print(f'{\"=\"*60}')\n\n    # Validation metrics\n    agg = summary.get('aggregated_val_metrics', {})\n    if agg:\n        print(f'\\n  Validation Set:')\n        for model, metrics in agg.items():\n            mae = metrics.get('MAE', {})\n            mse = metrics.get('MSE', {})\n            print(f'    {model:12s}  MAE = {mae.get(\"mean\",0):.6f} +/- {mae.get(\"std\",0):.6f}  '\n                  f'MSE = {mse.get(\"mean\",0):.6f} +/- {mse.get(\"std\",0):.6f}')\n\n    # Test metrics\n    test_agg = summary.get('aggregated_test_metrics', {})\n    if test_agg:\n        print(f'\\n  Test Set:')\n        for model, metrics in test_agg.items():\n            mae = metrics.get('MAE', {})\n            mse = metrics.get('MSE', {})\n            print(f'    {model:12s}  MAE = {mae.get(\"mean\",0):.6f} +/- {mae.get(\"std\",0):.6f}  '\n                  f'MSE = {mse.get(\"mean\",0):.6f} +/- {mse.get(\"std\",0):.6f}')\n\n    print(f'\\n  Best configs:')\n    for model, cfg in summary.get('best_configs', {}).items():\n        print(f'    {model}: {cfg}')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 15: Show CSV metrics tables (both markets, val + test)\nimport os\n\nfor market in ['gbm', 'heston']:\n    for split, fname in [('Validation', 'val_metrics_summary.csv'),\n                         ('Test', 'test_metrics_summary.csv')]:\n        csv_path = f'outputs/{market}/{fname}'\n        if os.path.exists(csv_path):\n            print(f'\\n=== {market.upper()} — {split} ===')\n            with open(csv_path) as f:\n                print(f.read())\n        else:\n            print(f'{market.upper()} — {split}: No CSV summary found.')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Model Comparison: Histograms + Violin Plots (GBM vs Heston)\n\n**7 comparison figures** using real experiment terminal errors:\n- **9a**: Terminal error histogram overlay per market (3 models overlaid)\n- **9b**: Violin + box plot of terminal errors per market\n- **9c**: Cross-market violin — same model, GBM vs Heston side-by-side\n- **9d**: Cross-market histogram overlay per model\n- **9e**: Shortfall distribution violin with CVaR95 annotations\n- **9f**: Grouped bar chart — MAE, Mean Shortfall, P(V_T >= H) across markets\n- **9g**: Grand combined violin — all 6 model-market combinations",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 17: Load terminal errors from experiment outputs\nimport json, os, numpy as np\nimport matplotlib.pyplot as plt\n\ndef load_experiment_errors():\n    \"\"\"Load terminal errors from experiment outputs (GBM and Heston).\n    Falls back to simulated data if experiment hasn't run yet.\n    \"\"\"\n    cross_path = os.path.join(os.getcwd(), 'outputs', 'cross_market', 'cross_market_errors.json')\n\n    if os.path.exists(cross_path):\n        with open(cross_path) as f:\n            raw = json.load(f)\n        data = {}\n        for mkt, models in raw.items():\n            data[mkt] = {m: np.array(e) for m, e in models.items()}\n        return data\n\n    # Fallback: generate representative simulated data\n    print('No experiment outputs found — using simulated representative data.')\n    np.random.seed(2026)\n    n = 2000\n    data = {\n        'gbm': {\n            'FNN': np.random.normal(0.02, 0.08, n),\n            'GRU': np.random.normal(0.01, 0.04, n),\n            'Regression': np.random.normal(0.03, 0.10, n),\n        },\n        'heston': {\n            'FNN': np.random.normal(0.01, 0.12, n),\n            'GRU': np.random.normal(0.005, 0.06, n),\n            'Regression': np.random.normal(0.02, 0.15, n),\n        },\n    }\n    return data\n\nerrors = load_experiment_errors()\nmodels = list(errors.get('gbm', {}).keys())\nmarkets = list(errors.keys())\nprint(f'Markets: {markets}')\nprint(f'Models: {models}')\nfor mkt in markets:\n    for m in models:\n        e = errors[mkt][m]\n        print(f'  {mkt}/{m}: n={len(e)}, mean={e.mean():.4f}, std={e.std():.4f}')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 18: Generate all 7 comparison plots (histogram + violin)\ndef plot_all_comparisons(errors, save_dir='Figures'):\n    \"\"\"Generate all histogram + violin comparison plots.\"\"\"\n    os.makedirs(save_dir, exist_ok=True)\n    models = list(errors.get('gbm', errors.get('heston', {})).keys())\n    markets = list(errors.keys())\n\n    c_model = {'FNN': '#5C6BC0', 'GRU': '#26A69A', 'Regression': '#FF8F00'}\n    c_market = {'gbm': '#1565C0', 'heston': '#8E24AA'}\n\n    # ── FIGURE 9a: Terminal Error Histogram Overlay (per market) ──\n    fig, axes = plt.subplots(1, len(markets), figsize=(9*len(markets), 6), sharey=True)\n    if len(markets) == 1: axes = [axes]\n    for ax, mkt in zip(axes, markets):\n        for m in models:\n            e = errors[mkt][m]\n            ax.hist(e, bins=60, density=True, alpha=0.4, color=c_model[m], label=m)\n            ax.axvline(e.mean(), color=c_model[m], linestyle='--', linewidth=1.5, alpha=0.8)\n        ax.axvline(0, color='black', linewidth=1.5, label='$V_T = \\\\tilde{H}$')\n        ax.set_xlabel('Terminal Error $e_T = V_T - \\\\tilde{H}$', fontsize=11)\n        ax.set_ylabel('Density', fontsize=11)\n        ax.set_title(f'{mkt.upper()}: Terminal Error Distribution', fontsize=13, fontweight='bold')\n        ax.legend(fontsize=9); ax.grid(True, alpha=0.3)\n    fig.suptitle('(9a) Terminal Error Histogram: Model Comparison', fontsize=15, fontweight='bold', y=1.02)\n    fig.tight_layout()\n    fig.savefig(os.path.join(save_dir, 'comparison_histogram_by_model.png'), dpi=200, bbox_inches='tight')\n    plt.show()\n\n    # ── FIGURE 9b: Violin Plot — Terminal Errors by Model (per market) ──\n    fig, axes = plt.subplots(1, len(markets), figsize=(8*len(markets), 6), sharey=True)\n    if len(markets) == 1: axes = [axes]\n    for ax, mkt in zip(axes, markets):\n        data_list = [errors[mkt][m] for m in models]\n        parts = ax.violinplot(data_list, positions=range(len(models)), showmeans=True,\n                             showmedians=True, showextrema=False)\n        for i, pc in enumerate(parts['bodies']):\n            pc.set_facecolor(c_model[models[i]]); pc.set_alpha(0.6)\n        parts['cmeans'].set_color('#C62828'); parts['cmedians'].set_color('#1B5E20')\n        bp = ax.boxplot(data_list, positions=range(len(models)), widths=0.15,\n                       patch_artist=True, showfliers=False, zorder=5)\n        for i, patch in enumerate(bp['boxes']):\n            patch.set_facecolor(c_model[models[i]]); patch.set_alpha(0.8)\n        ax.axhline(0, color='black', linewidth=1, linestyle='--', alpha=0.5)\n        ax.set_xticks(range(len(models))); ax.set_xticklabels(models, fontsize=11)\n        ax.set_ylabel('Terminal Error $e_T$', fontsize=11)\n        ax.set_title(f'{mkt.upper()}: Violin + Box Plot', fontsize=13, fontweight='bold')\n        ax.grid(True, alpha=0.3, axis='y')\n    fig.suptitle('(9b) Terminal Error Distribution: Violin Plots', fontsize=15, fontweight='bold', y=1.02)\n    fig.tight_layout()\n    fig.savefig(os.path.join(save_dir, 'comparison_violin_by_model.png'), dpi=200, bbox_inches='tight')\n    plt.show()\n\n    # ── FIGURE 9c: Cross-Market Violin — Same model, GBM vs Heston ──\n    if len(markets) >= 2:\n        fig, axes = plt.subplots(1, len(models), figsize=(7*len(models), 6), sharey=True)\n        if len(models) == 1: axes = [axes]\n        for ax, m in zip(axes, models):\n            data_list = [errors[mkt][m] for mkt in markets]\n            parts = ax.violinplot(data_list, positions=range(len(markets)), showmeans=True,\n                                 showmedians=True, showextrema=False)\n            for i, pc in enumerate(parts['bodies']):\n                pc.set_facecolor(c_market[markets[i]]); pc.set_alpha(0.6)\n            parts['cmeans'].set_color('#C62828'); parts['cmedians'].set_color('#1B5E20')\n            bp = ax.boxplot(data_list, positions=range(len(markets)), widths=0.15,\n                           patch_artist=True, showfliers=False, zorder=5)\n            for i, patch in enumerate(bp['boxes']):\n                patch.set_facecolor(c_market[markets[i]]); patch.set_alpha(0.8)\n            ax.axhline(0, color='black', linewidth=1, linestyle='--', alpha=0.5)\n            ax.set_xticks(range(len(markets)))\n            ax.set_xticklabels([mk.upper() for mk in markets], fontsize=11)\n            ax.set_ylabel('Terminal Error $e_T$', fontsize=11)\n            ax.set_title(f'{m}: GBM vs Heston', fontsize=13, fontweight='bold')\n            ax.grid(True, alpha=0.3, axis='y')\n        fig.suptitle('(9c) Cross-Market Comparison: GBM vs Heston per Model',\n                     fontsize=15, fontweight='bold', y=1.02)\n        fig.tight_layout()\n        fig.savefig(os.path.join(save_dir, 'comparison_violin_cross_market.png'), dpi=200, bbox_inches='tight')\n        plt.show()\n\n    # ── FIGURE 9d: Cross-Market Histogram Overlay (per model) ──\n    if len(markets) >= 2:\n        fig, axes = plt.subplots(1, len(models), figsize=(7*len(models), 5), sharey=True)\n        if len(models) == 1: axes = [axes]\n        for ax, m in zip(axes, models):\n            for mkt in markets:\n                e = errors[mkt][m]\n                ax.hist(e, bins=50, density=True, alpha=0.45, color=c_market[mkt],\n                       label=f'{mkt.upper()} (mean={e.mean():.3f})')\n            ax.axvline(0, color='black', linewidth=1.5)\n            ax.set_xlabel('Terminal Error $e_T$', fontsize=11)\n            ax.set_ylabel('Density', fontsize=11)\n            ax.set_title(f'{m}', fontsize=13, fontweight='bold')\n            ax.legend(fontsize=9); ax.grid(True, alpha=0.3)\n        fig.suptitle('(9d) Cross-Market Histogram: GBM vs Heston per Model',\n                     fontsize=15, fontweight='bold', y=1.02)\n        fig.tight_layout()\n        fig.savefig(os.path.join(save_dir, 'comparison_histogram_cross_market.png'), dpi=200, bbox_inches='tight')\n        plt.show()\n\n    # ── FIGURE 9e: Shortfall Distribution Violin (per market) ──\n    fig, axes = plt.subplots(1, len(markets), figsize=(8*len(markets), 6), sharey=True)\n    if len(markets) == 1: axes = [axes]\n    for ax, mkt in zip(axes, markets):\n        shortfalls = [np.maximum(-errors[mkt][m], 0) for m in models]\n        parts = ax.violinplot(shortfalls, positions=range(len(models)),\n                             showmeans=True, showmedians=True, showextrema=False)\n        for i, pc in enumerate(parts['bodies']):\n            pc.set_facecolor(c_model[models[i]]); pc.set_alpha(0.6)\n        parts['cmeans'].set_color('#C62828'); parts['cmedians'].set_color('#1B5E20')\n        for i, m in enumerate(models):\n            s = np.maximum(-errors[mkt][m], 0)\n            s_sorted = np.sort(s)[::-1]\n            k = max(1, int(0.05 * len(s)))\n            cvar95 = s_sorted[:k].mean()\n            ax.annotate(f'CVaR$_{{95}}$={cvar95:.3f}', xy=(i, cvar95),\n                       fontsize=8, ha='center', va='bottom', color='#C62828', fontweight='bold')\n        ax.set_xticks(range(len(models))); ax.set_xticklabels(models, fontsize=11)\n        ax.set_ylabel('Shortfall $s = \\\\max(\\\\tilde{H} - V_T, 0)$', fontsize=11)\n        ax.set_title(f'{mkt.upper()}: Shortfall Distribution', fontsize=13, fontweight='bold')\n        ax.grid(True, alpha=0.3, axis='y')\n    fig.suptitle('(9e) Shortfall Distribution: Violin Plots with CVaR$_{95}$',\n                 fontsize=15, fontweight='bold', y=1.02)\n    fig.tight_layout()\n    fig.savefig(os.path.join(save_dir, 'comparison_violin_shortfall.png'), dpi=200, bbox_inches='tight')\n    plt.show()\n\n    # ── FIGURE 9f: Grouped Metric Bar Chart ──\n    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n    x = np.arange(len(models)); width = 0.35\n    ax = axes[0]\n    for i, mkt in enumerate(markets):\n        maes = [np.abs(errors[mkt][m]).mean() for m in models]\n        ax.bar(x + i*width - width/2*(len(markets)-1), maes, width,\n               label=mkt.upper(), color=c_market[mkt], alpha=0.85, edgecolor='black')\n    ax.set_xticks(x); ax.set_xticklabels(models, fontsize=11)\n    ax.set_ylabel('MAE', fontsize=11)\n    ax.set_title('Mean Absolute Error', fontsize=13, fontweight='bold')\n    ax.legend(fontsize=10); ax.grid(True, alpha=0.3, axis='y')\n    ax = axes[1]\n    for i, mkt in enumerate(markets):\n        shortfalls = [np.maximum(-errors[mkt][m], 0).mean() for m in models]\n        ax.bar(x + i*width - width/2*(len(markets)-1), shortfalls, width,\n               label=mkt.upper(), color=c_market[mkt], alpha=0.85, edgecolor='black')\n    ax.set_xticks(x); ax.set_xticklabels(models, fontsize=11)\n    ax.set_ylabel('Mean Shortfall', fontsize=11)\n    ax.set_title('Mean Shortfall $\\\\mathbb{E}[s]$', fontsize=13, fontweight='bold')\n    ax.legend(fontsize=10); ax.grid(True, alpha=0.3, axis='y')\n    ax = axes[2]\n    for i, mkt in enumerate(markets):\n        probs = [(errors[mkt][m] >= 0).mean() for m in models]\n        ax.bar(x + i*width - width/2*(len(markets)-1), probs, width,\n               label=mkt.upper(), color=c_market[mkt], alpha=0.85, edgecolor='black')\n    ax.set_xticks(x); ax.set_xticklabels(models, fontsize=11)\n    ax.set_ylabel('$P(V_T \\\\geq \\\\tilde{H})$', fontsize=11)\n    ax.set_title('Super-Hedging Success Rate', fontsize=13, fontweight='bold')\n    ax.axhline(1.0, color='gray', linestyle=':', alpha=0.5)\n    ax.legend(fontsize=10); ax.grid(True, alpha=0.3, axis='y')\n    fig.suptitle('(9f) Key Metrics: GBM vs Heston across Models',\n                 fontsize=15, fontweight='bold', y=1.02)\n    fig.tight_layout()\n    fig.savefig(os.path.join(save_dir, 'comparison_metrics_bars.png'), dpi=200, bbox_inches='tight')\n    plt.show()\n\n    # ── FIGURE 9g: Combined 6-Model Violin ──\n    fig, ax = plt.subplots(figsize=(14, 7))\n    all_data, all_labels, all_colours = [], [], []\n    for mkt in markets:\n        for m in models:\n            all_data.append(errors[mkt][m])\n            all_labels.append(f'{m}\\n({mkt.upper()})')\n            all_colours.append(c_market[mkt])\n    positions = range(len(all_data))\n    parts = ax.violinplot(all_data, positions=positions, showmeans=True,\n                         showmedians=True, showextrema=False)\n    for i, pc in enumerate(parts['bodies']):\n        pc.set_facecolor(all_colours[i]); pc.set_alpha(0.55)\n    parts['cmeans'].set_color('#C62828'); parts['cmedians'].set_color('#1B5E20')\n    bp = ax.boxplot(all_data, positions=positions, widths=0.12,\n                   patch_artist=True, showfliers=False, zorder=5)\n    for i, patch in enumerate(bp['boxes']):\n        patch.set_facecolor(all_colours[i]); patch.set_alpha(0.8)\n    ax.axhline(0, color='black', linewidth=1.5, linestyle='--', alpha=0.6)\n    ax.set_xticks(positions); ax.set_xticklabels(all_labels, fontsize=10)\n    ax.set_ylabel('Terminal Error $e_T$', fontsize=12)\n    ax.set_title('All Models x Markets: Terminal Error Distribution', fontsize=14, fontweight='bold')\n    ax.grid(True, alpha=0.3, axis='y')\n    if len(markets) >= 2:\n        sep_x = len(models) - 0.5\n        ax.axvline(sep_x, color='gray', linewidth=2, linestyle='-', alpha=0.4)\n        ax.text(sep_x/2, ax.get_ylim()[1]*0.9, 'GBM', ha='center',\n               fontsize=12, fontweight='bold', color=c_market['gbm'])\n        ax.text(sep_x + len(models)/2, ax.get_ylim()[1]*0.9, 'HESTON', ha='center',\n               fontsize=12, fontweight='bold', color=c_market.get('heston', '#8E24AA'))\n    fig.suptitle('(9g) Grand Comparison: All Models under Both Markets',\n                 fontsize=15, fontweight='bold', y=1.01)\n    fig.tight_layout()\n    fig.savefig(os.path.join(save_dir, 'comparison_grand_violin.png'), dpi=200, bbox_inches='tight')\n    plt.show()\n\nplot_all_comparisons(errors)\nprint('\\nAll 7 comparison figures saved to Figures/')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 19: Download all outputs as zip (includes GBM, Heston, cross_market)\nimport shutil\nfrom google.colab import files\n\nshutil.make_archive('outputs', 'zip', '.', 'outputs')\nfiles.download('outputs.zip')",
   "execution_count": null,
   "outputs": []
  }
 ]
}